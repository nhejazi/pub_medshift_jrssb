
R version 3.4.2 (2017-09-28) -- "Short Summer"
Copyright (C) 2017 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

[Previously saved workspace restored]

R > # packages
R > library(here)
here() starts at /global/home/users/nhejazi/medshift-meta/application
R > library(tidyverse)  # pandoc can't deal with the startup message
-- Attaching packages ---------------------------------- tidyverse 1.2.1.9000 --
v ggplot2 3.1.0     v purrr   0.2.5
v tibble  1.4.2     v dplyr   0.7.8
v tidyr   0.8.2     v stringr 1.3.1
v readr   1.3.1     v forcats 0.3.0
-- Conflicts ------------------------------------------ tidyverse_conflicts() --
x dplyr::filter() masks stats::filter()
x dplyr::lag()    masks stats::lag()
R > library(data.table)

Attaching package: 'data.table'

The following objects are masked from 'package:dplyr':

    between, first, last

The following object is masked from 'package:purrr':

    transpose

R > library(SuperLearner)
Loading required package: nnls
Super Learner
Version: 2.0-24
Package created on 2018-08-10

R > library(sl3)
R > library(medshift)
medshift v0.0.8: Causal Mediation Analysis for Stochastic Interventions
R > library(npcausal)
R > library(mma)
Loading required package: gbm
Loaded gbm 2.1.4
Loading required package: splines
Loading required package: survival
Loading required package: car
Loading required package: carData

Attaching package: 'car'

The following object is masked from 'package:dplyr':

    recode

The following object is masked from 'package:purrr':

    some

Loading required package: gplots

Attaching package: 'gplots'

The following object is masked from 'package:stats':

    lowess

R > library(future)

Attaching package: 'future'

The following object is masked from 'package:survival':

    cluster

R > 
R > # options: parallelization, prng, etc
R > options(scipen = 999)  ## has scientific notation ever annoyed you?
R > sl3_debug_mode()
R > plan(multiprocess)
R > set.seed(429153)
R > 
R > # convenience function to compute inference via delta method: EY1 - EY0
R > param_linear_contrast <- function(params, eifs, ci_level = 0.95) {
...   # bounds for confidence interval
...   ci_norm_bounds <- c(-1, 1) * abs(stats::qnorm(p = (1 - ci_level) / 2))
...   param_est <- params[[1]] - params[[2]]
...   eif <- eifs[[1]] - eifs[[2]]
...   se_eif <- sqrt(var(eif) / length(eif))
...   param_ci <- param_est + ci_norm_bounds * se_eif
...   # parameter and inference
...   out <- c(param_ci[1], param_est, param_ci[2])
...   names(out) <- c("lwr_ci", "param_est", "upr_ci")
...   return(out)
... }
R > 
R > data(weight_behavior)
R > dim(weight_behavior)
[1] 691  15
R > head(weight_behavior)
       bmi  age sex  race numpeople car gotosch snack tvhours cmpthours
1 18.20665 12.2   F OTHER         5   3       2     1       4         0
2 22.78401 12.8   M OTHER         4   3       2     1       4         2
3 19.60725 12.6   F OTHER         4   2       4     2      NA        NA
4 25.56754 12.1   M OTHER         2   3       2     1       0         2
5 15.07408 12.3   M OTHER         4   1       2     1       2         1
6 22.98338 11.8   M OTHER         4   1       1     1       4         3
  cellhours sports exercises sweat overweigh
1         0      2         2     1         0
2         0      1         8     2         0
3        NA   <NA>         4     2         0
4         0      2         9     1         1
5         3      1        12     1         0
6         2      1         1     1         0
R > 
R > # remove missing values
R > is_na <- unique(do.call(c, apply(apply(weight_behavior, 2, is.na), 2, which)))
R > weight_behavior_complete <- weight_behavior[-is_na, ]
R > weight_behavior_complete$sports <-
...   as.numeric(weight_behavior_complete$sports) - 1
R > dim(weight_behavior_complete)
[1] 567  15
R > head(weight_behavior_complete)
       bmi  age sex  race numpeople car gotosch snack tvhours cmpthours
1 18.20665 12.2   F OTHER         5   3       2     1       4         0
2 22.78401 12.8   M OTHER         4   3       2     1       4         2
4 25.56754 12.1   M OTHER         2   3       2     1       0         2
5 15.07408 12.3   M OTHER         4   1       2     1       2         1
6 22.98338 11.8   M OTHER         4   1       1     1       4         3
8 19.15658 12.1   F OTHER         3   3       2     1       0         0
  cellhours sports exercises sweat overweigh
1         0      1         2     1         0
2         0      0         8     2         0
4         0      1         9     1         1
5         3      0        12     1         0
6         2      0         1     1         0
8         1      0         1     3         0
R > 
R > Y <- weight_behavior_complete$bmi
R > A <- weight_behavior_complete$sports
R > Z <- weight_behavior_complete %>%
...   select(snack, exercises, overweigh)
R > W <- weight_behavior_complete %>%
...   select(age, sex, race, numpeople, car, gotosch, tvhours, cmpthours,
...          cellhours, sweat)
R > 
R > delta_shift_ipsi <- 0.25
R > 
R > # random forest learner based on ranger
R > mean_lrnr <- Lrnr_mean$new()
R > rf_lrnr_50trees <- Lrnr_ranger$new(num.trees = 50)
R > rf_lrnr_100trees <- Lrnr_ranger$new(num.trees = 100)
R > rf_lrnr_500trees <- Lrnr_ranger$new(num.trees = 500)
R > 
R > # SL learners used for continuous data (the nuisance parameter M)
R > fglm_contin_lrnr <- Lrnr_glm_fast$new(family = gaussian())
R > ridge_contin_lrnr <- Lrnr_glmnet$new(alpha = 0, family = "gaussian")
R > enet_contin_lrnr <- Lrnr_glmnet$new(alpha = 0.5, family = "gaussian")
R > lasso_contin_lrnr <- Lrnr_glmnet$new(alpha = 1, family = "gaussian")
R > xgboost_lrnr_50_contin <- Lrnr_xgboost$new(nrounds = 50,
...                                            objective = "reg:linear")
R > xgboost_lrnr_100_contin <- Lrnr_xgboost$new(nrounds = 100,
...                                             objective = "reg:linear")
R > xgboost_lrnr_300_contin <- Lrnr_xgboost$new(nrounds = 300,
...                                             objective = "reg:linear")
R > hal_deg3_contin <- Lrnr_hal9001$new(n_folds = 5, degrees = 3,
...                                     fit_type = "glmnet")
R > hal_deg5_contin <- Lrnr_hal9001$new(n_folds = 5, degrees = 5,
...                                     fit_type = "glmnet")
R > contin_lrnr_lib <- Stack$new(mean_lrnr,
...                              fglm_contin_lrnr,
...                              ridge_contin_lrnr,
...                              enet_contin_lrnr,
...                              lasso_contin_lrnr,
...                              hal_deg3_contin,
...                              hal_deg5_contin,
...                              xgboost_lrnr_50_contin,
...                              xgboost_lrnr_100_contin,
...                              xgboost_lrnr_300_contin,
...                              rf_lrnr_50trees,
...                              rf_lrnr_100trees,
...                              rf_lrnr_500trees)
R > sl_contin_lrnr <- Lrnr_sl$new(learners = contin_lrnr_lib,
...                               metalearner = Lrnr_nnls$new())
R > 
R > # SL learners used for binary data (nuisance parameters G and E in this case)
R > fglm_binary_lrnr <- Lrnr_glm_fast$new(family = binomial())
R > ridge_binary_lrnr <- Lrnr_glmnet$new(alpha = 0, family = "binomial")
R > enet_binary_lrnr <- Lrnr_glmnet$new(alpha = 0.5, family = "binomial")
R > lasso_binary_lrnr <- Lrnr_glmnet$new(alpha = 1, family = "binomial")
R > xgboost_lrnr_50_binary <- Lrnr_xgboost$new(nrounds = 50,
...                                            objective = "reg:logistic")
R > xgboost_lrnr_100_binary <- Lrnr_xgboost$new(nrounds = 100,
...                                             objective = "reg:logistic")
R > xgboost_lrnr_300_binary <- Lrnr_xgboost$new(nrounds = 300,
...                                             objective = "reg:logistic")
R > hal_deg3_binary <- Lrnr_hal9001$new(n_folds = 5, degrees = 3,
...                                     fit_type = "glmnet", family = "binomial")
R > hal_deg5_binary <- Lrnr_hal9001$new(n_folds = 5, degrees = 5,
...                                     fit_type = "glmnet", family = "binomial")
R > binary_lrnr_lib <- Stack$new(mean_lrnr,
...                              fglm_binary_lrnr,
...                              ridge_binary_lrnr,
...                              enet_binary_lrnr,
...                              lasso_binary_lrnr,
...                              hal_deg3_binary,
...                              hal_deg5_binary,
...                              xgboost_lrnr_50_binary,
...                              xgboost_lrnr_100_binary,
...                              xgboost_lrnr_300_binary,
...                              rf_lrnr_50trees,
...                              rf_lrnr_100trees,
...                              rf_lrnr_500trees)
R > sl_binary_lrnr <- Lrnr_sl$new(learners = binary_lrnr_lib,
...                               metalearner = Lrnr_nnls$new())
R > 
R > # let's compute the parameter where both A and Z are shifted
R > psi_ipsi_fit <- ipsi(y = Y, a = A, x.trt = W, x.out = W,
...                      time = rep(1, length(Y)), id = seq_along(Y),
...                      delta.seq = delta_shift_ipsi, nsplits = 10,
...                      progress_bar = FALSE, return_ifvals = TRUE)
R > 
R > # print return object and extract point estimate
R > psi_ipsi_param <- psi_ipsi_fit$res$est
R > psi_ipsi_ci <- c(psi_ipsi_fit$res$ci.ll, psi_ipsi_fit$res$ci.ul)
R > psi_ipsi_eif <- as.numeric(psi_ipsi_fit$ifvals)
R > psi_ipsi_fit$res
    increment      est       se    ci.ll    ci.ul
95%      0.25 18.88448 3.767077 18.57666 19.19229
R > 
R > 
R > # let's compute the parameter where A (but not Z) are shifted
R > medshift_start <- proc.time()
R > theta_eff <- medshift(W = W, A = A, Z = Z, Y = Y,
...                       delta = delta_shift_ipsi,
...                       g = sl_binary_lrnr,
...                       e = sl_binary_lrnr,
...                       m = sl_contin_lrnr,
...                       phi = fglm_contin_lrnr,
...                       estimator = "onestep",
...                       estimator_args = list(cv_folds = 10))
R > medshift_end <- proc.time()
R > theta_eff
$theta
[1] 19.02609

$var
[1] 0.02635621

$type
[1] "one-step efficient"

R > (medshift_time <- medshift_end - medshift_start)
     user    system   elapsed 
16556.335   823.077 10637.104 
R > 
R > # parameter estimates and EIFs for components of direct effect
R > EY <- mean(Y)
R > eif_EY <- Y - EY
R > params_nde <- list(EY, theta_eff$theta)
R > eifs_nde <- list(eif_EY, theta_eff$eif)
R > 
R > # natural direct effect = EY - estimated quantity
R > nde_est <- param_linear_contrast(params_nde, eifs_nde)
R > nde_est
    lwr_ci  param_est     upr_ci 
-0.3483205  0.1010144  0.5503493 
R > 
R > 
R > # parameter estimates and EIFs for components of indirect effect
R > params_nie <- list(theta_eff$theta, psi_ipsi_param)
R > eifs_nie <- list(theta_eff$eif, psi_ipsi_eif)
R > 
R > # natural indirect effect = estimated quantity - Edward's estimate
R > nie_est <- param_linear_contrast(params_nie, eifs_nie)
R > nie_est
    lwr_ci  param_est     upr_ci 
-0.2969940  0.1416165  0.5802270 
R > 
R > 
R > # save output
R > objects_save <- list(nde_estim = nde_est, nie_estim = nie_est,
...                      nde_param = params_nde, nde_eif = eifs_nde,
...                      nie_param = params_nie, nie_eif = eifs_nie,
...                      medshift = theta_eff, ipsi = psi_ipsi_fit,
...                      EY = EY, EY_eif = eif_EY)
R > saveRDS(objects_save,
...         file = here("data", "simple_example_results.rds"))
R > 
R > 
> proc.time()
     user    system   elapsed 
16573.597   824.161 10651.820 
Warning message:
system call failed: Cannot allocate memory 
